{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:left\">\n",
    "    <h1 style=\"width:450px\">Practical 4: Object-Oriented Programming</h1>\n",
    "    <h2 style=\"width:450px\">Getting to grips with Functions &amp; Packages</h2>\n",
    "</div>\n",
    "<div style=\"float:right\"><img width=\"100\" src=\"https://github.com/jreades/i2p/raw/master/img/casa_logo.jpg\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>&#9888; Important</b>: This is a very long practical and it's <em>not</em> expected that you will get through it in the alloted time. The priorities here should be tasks 1--4. Task 5 is something you will probably want to revist before the start of group work (because packges of functions are useful when multiple people are working on the same code). Task 6 will help you to understand <i>how</i> to build your own classes in greater detail, but it is enough to understand that classes exist in hierarchies (as covered in the live session).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (Revisited). Why 'Obvious' is Not Always 'Right'\n",
    "\n",
    "Practical 3 is hard, so I want to provide _another_ chance for the concepts to bed in before we use them in an *object-oriented way through Pandas*. Yes, Week 5 will show how we combine concepts covered over the preceding two weeks in *practice* to do data science. \n",
    "\n",
    "So remember the finding from last week: if we don't really care about column order, then a dictionary of lists would be a nice way to handle data. And why should we care about column order? With our CSV file we saw what a pain it was to fix things when even a tiny thing like the layout of the columns changed. But if, instead, we could just reference the 'Description' column in the data set then it doesn't matter where that column actually is *and* we would know that all the descriptions would be *text*, while all the populations or prices would be *numbers*. Why is that? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1 The Way That Doesn't Work\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low (this time around).</div>\n",
    "\n",
    "Here are four rows of 'data' for city sizes organised by _row_ as a list-of-lists. Try printing out *just* the cities contained in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Âú®week3 Âü∫Á°Ä‰∏äÁöÑÁªÉ‰π†üòä\n",
    "\n",
    "myData = [\n",
    "    ['id', 'Name', 'Rank', 'Longitude', 'Latitude', 'Population'], \n",
    "    ['1', 'Greater London', '1', '-18162.92767', '6711153.709', '9787426'], \n",
    "    ['2', 'Greater Manchester', '2', '-251761.802', '7073067.458', '2553379'], \n",
    "    ['3', 'West Midlands', '3', '-210635.2396', '6878950.083', '2440986']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Print a List of Cities\n",
    "\n",
    "Print out a list of every city in the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cities in the data set are: Greater London, Greater Manchester, West Midlands\n"
     ]
    }
   ],
   "source": [
    "col    = myData[0].index('Name')\n",
    "cities = []\n",
    "\n",
    "# for i in range(1,4):cities.append...\n",
    "\n",
    "for i in range(1, len(myData)):\n",
    "    cities.append(myData[i][col])\n",
    "    \n",
    "print(\"The cities in the data set are: \" + \", \".join(cities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Is Edinburgh in the List?\n",
    "\n",
    "Now write code to find out if `Edinburgh` is included in the list of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Didn't find Edinburgh in the data set.\n"
     ]
    }
   ],
   "source": [
    "found = False\n",
    "for i in range(1, len(myData)):\n",
    "    if myData[i][col] == 'Edinburgh':\n",
    "        print(\"Found Edinburgh in the data set!\")\n",
    "        found = True\n",
    "        break\n",
    "\n",
    "if found == False:\n",
    "    print(\"Didn't find Edinburgh in the data set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2 The Way That Does Work\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low (this time around).</div>\n",
    "\n",
    "Compare that code to how it works for a dictionary-of-lists organised by _column_. Now try printing out the cities in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = {\n",
    "    'id'         : [0, 1, 2, 3, 4, 5],\n",
    "    'Name'       : ['Greater London', 'Greater Manchester', 'Birmingham','Edinburgh','Inverness','Lerwick'],\n",
    "    'Rank'       : [1, 2, 3, 4, 5, 6],\n",
    "    'Longitude'  : [-0.128, -2.245, -1.903, -3.189, -4.223, -1.145],\n",
    "    'Latitude'   : [51.507, 53.479, 52.480, 55.953, 57.478, 60.155],\n",
    "    'Population' : [9787426, 2705000, 1141816, 901455, 70000, 6958],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Print a List of Cities\n",
    "\n",
    "Print out a list of every city in the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greater London, Greater Manchester, Birmingham, Edinburgh, Inverness, Lerwick\n"
     ]
    }
   ],
   "source": [
    "# ÁªßÁª≠‰ª•ÁªÉ‰π†ÊñπÂºèËØÅÊòéweek3 ÊèêÂà∞ÁöÑdictionaries Â•ΩÂ§Ñ üëá\n",
    "\n",
    "# What cities are in the data set?\n",
    "print(\", \".join(myData['Name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Is Edinburgh in the List?\n",
    "\n",
    "Now write code to find out if `Edinburgh` is included in the list of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Edinburgh in the data set!\n"
     ]
    }
   ],
   "source": [
    "if 'Edinburgh' in myData['Name']:\n",
    "    print(\"Found Edinburgh in the data set!\")\n",
    "else:\n",
    "    print(\"Didn't find Edinburgh in the data set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how even basic questions like \"Is Edinburgh in our list of data?\" are suddenly easy to answer? We no longer need to loop over the entire data set in order to find one data point. In addition, we know that everything in the 'Name' column will be a string, and that everything in the 'Longitude' column is a float, while the 'Population' column contains integers. So that's made life easier already. But let's test this out and see how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3 Appending a Column\n",
    "\n",
    "To give you a sense of how scaleable this approach to data is let's add a new column where the population is standardised to a z-score. Remember that the format for the z-score is: \n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\bar{x}}{\\mu}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Calculate Mean & Std Dev\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low-ish.</div>\n",
    "\n",
    "Let's start by calculating the sample mean and standard deviation (use Google: `Python numpy mean...`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City distribution has a mean 2,435,442 and standard deviation of 3,406,947.93.\n"
     ]
    }
   ],
   "source": [
    "# ‰ΩøÁî®numpyËÆ°ÁÆóÊï∞ÊçÆ üê±\n",
    "# meanÂπ≥ÂùáÂÄº stdÊ†áÂáÜÂÄº\n",
    "# {std:,.2f}  2f‰øùÁïôÂ∞èÊï∞ÁÇπÂêé2‰Ωç\n",
    "\n",
    "import numpy as np\n",
    "# Use numpy functions to calculate mean and standard deviation\n",
    "mean = np.mean(myData['Population'])\n",
    "std  = np.std(myData['Population'])\n",
    "print(f\"City distribution has a mean {mean:,.0f} and standard deviation of {std:,.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` gives us a way to calculate the mean and standard deviation _quickly_ and without having to reinvent the wheel. The other potentially new thing here is `{std:,.2f}`. This is about [string formatting](https://www.w3schools.com/python/ref_string_format.asp) and the main thing to recognise is that this means 'format this float with commas separating the thousands/millions and 2 digits to the right'. The link I've provided uses the slightly older approach of `<str>.format()` but the formatting approach is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 For Loops Without For Loops\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Difficulty level</b>: Medium.</div>\n",
    "\n",
    "Now we're going to see something called a **List Comprehension**.\n",
    "\n",
    "In Python you will see code like this a lot: `[x for x in list]`. This syntax is known as a 'list comprehension' and is basically a `for` loop on one line with the output being assigned to a list. So we can apply an operation (converting to a string, subtracting a value, etc.) to every item in a list without writing out a full for loop.\n",
    "\n",
    "Here's a quick example just to show you what's going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "# forÂæ™ÁéØ üåô\n",
    "# [x for x in list]  \n",
    "# Á¨¨‰∫å‰∏™ xÊòØËÆæÂÆöÁöÑÔºåÂ≠òÂú®ÊüêÊï∞ÊçÆÂàóË°®‰∏≠Ôºå‰ΩÜ‰∏çÊåáÂÆöÊòØÂì™‰∏™Êï∞ÊçÆ\n",
    "# Á¨¨‰∏Ä‰∏™ xÊòØËÆæÂÆöxÁöÑËÆ°ÁÆó/Êìç‰Ωú\n",
    "# ‰ΩøÁî®forÂæ™ÁéØÔºöÂàóË°®‰∏≠ÁöÑÊØè‰∏ÄÈ°πÂ∫îÁî®Á¨¨‰∏Ä‰∏™x ÁöÑËÆ°ÁÆó/Êìç‰Ωú\n",
    "\n",
    "\n",
    "demo = range(0,10) # <- a *range* of numbers between 0 and 9 (stop at 10)\n",
    "print([x**2 for x in demo]) # square every element of demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply this to our problem. We calculated the the mean and standard deviation above, so now we want to apply the z-score formula to every element of the Population list... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.158', '0.079', '-0.380', '-0.450', '-0.694', '-0.713']\n"
     ]
    }
   ],
   "source": [
    "# ÂØπÊ≠§È¢òËß£ËØª\n",
    "# xÂú®Êï∞ÊçÆ'Population' ÂàóË°®‰∏≠Ôºå‰ΩÜ‰∏çÊåáÂÆöÊòØÂì™‰∏™Êï∞ÊçÆ\n",
    "# Ôºàx - mean)/std = xÂáèÂéªmeanÈô§standard\n",
    "# 'Population'ÂàóË°®ÊØè‰∏ÄÊï∞ÊçÆÈÉΩËøô‰πàÂÅö\n",
    "\n",
    "rs = [(x - mean)/std for x in myData['Population']] # rs == result set\n",
    "print([f\"{x:.3f}\" for x in rs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Appending\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: trivial</div>\n",
    "\n",
    "And now let's add it to the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.1579383252868527, 0.0791199354729932, -0.3797024575689938, -0.45025269939207097, -0.6942995760276591, -0.7128035277711219]\n",
      "{'id': [0, 1, 2, 3, 4, 5], 'Name': ['Greater London', 'Greater Manchester', 'Birmingham', 'Edinburgh', 'Inverness', 'Lerwick'], 'Rank': [1, 2, 3, 4, 5, 6], 'Longitude': [-0.128, -2.245, -1.903, -3.189, -4.223, -1.145], 'Latitude': [51.507, 53.479, 52.48, 55.953, 57.478, 60.155], 'Population': [9787426, 2705000, 1141816, 901455, 70000, 6958], 'Std. Population': [2.1579383252868527, 0.0791199354729932, -0.3797024575689938, -0.45025269939207097, -0.6942995760276591, -0.7128035277711219]}\n"
     ]
    }
   ],
   "source": [
    "# ‰∏ä‰∏ÄÊ≠•ËÆ°ÁÆóÁöÑrsÂä†ÂÖ•Âà∞ÂéüÊï∞ÊçÆmyDataÈáå\n",
    "# ÈúÄË¶Å ÂÆö‰πâmyDataÁöÑ'Std.Population' ÊòØrs\n",
    "\n",
    "myData['Std. Population'] = rs\n",
    "print(myData['Std. Population'])\n",
    "print(myData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just to show how everything is in a single data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greater London has a population of 9,787,426 and standardised score of 2.158\n",
      "Greater Manchester has a population of 2,705,000 and standardised score of 0.079\n",
      "Birmingham has a population of 1,141,816 and standardised score of -0.380\n",
      "Edinburgh has a population of 901,455 and standardised score of -0.450\n",
      "Inverness has a population of 70,000 and standardised score of -0.694\n",
      "Lerwick has a population of 6,958 and standardised score of -0.713\n"
     ]
    }
   ],
   "source": [
    "# Â±ïÁ§∫Êï∞ÊçÆÁªìÊûÑ\n",
    "\n",
    "for c in myData['Name']:\n",
    "    idx = myData['Name'].index(c)\n",
    "    print(f\"{c} has a population of {myData['Population'][idx]:,} and standardised score of {myData['Std. Population'][idx]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. 'Functionalising'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start trying to pull what we've learned over the past two weeks together by creating a a set of functions that will help us to:\n",
    "\n",
    "1. Download a file from a URL (checking if it has already _been_ downloaded to save bandwidth).\n",
    "2. Parse it as a CSV file and...\n",
    "3. Convert it to a Dictionary-of-Lists\n",
    "4. Perform some simple calculations using the resulting data.\n",
    "\n",
    "To be honest, there's not going to be much about writing our _own_ objects here, but we will be making use of them and, conceptually, an understanding of objects and classes is going to be super-useful for understanding what we're doing in the remainder of the term!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Downloading from a URL\n",
    "\n",
    "Let's focus on the first part *first* because that's the precondition for everything else. If we can get the 'download a file from a URL' working then the rest will gradually fall into place through *iterative* improvments!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Finding an Existing Answer\n",
    "\n",
    "First, let's be sensibly lazy--we've already written code to read a file from the Internet and turn it into a list of lists. So I've copy+pasted that into the code block below since we're going to start from this point; however, just to help you check your own understanding, I've removed a few bits and replacement with `??`. Sorry. üòà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urlData has 11 rows and 4 columns.\n",
      "['Bangor', '18808', '53.228', '-4.128']\n"
     ]
    }
   ],
   "source": [
    "# ‰ªéURL‰∏ãËΩΩÂ≠ò‰∫éÁΩëÁ´ôÁöÑcsvÊï∞ÊçÆ ü¶Å\n",
    "# ÂêØÁî®urlopenÂäüËÉΩ\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import csv\n",
    "\n",
    "# urlËØªÂèñÊï∞ÊçÆ\n",
    "url = \"https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities-simple.csv\"\n",
    "\n",
    "# ÂÇ®Â≠òÊï∞ÊçÆ\n",
    "urlData = [] \n",
    "\n",
    "# Â∞Ü urlËØªÂÖ•Âêç‰∏∫'response'ÁöÑÂèòÈáè\n",
    "# ‰ªé response‰∏≠ËØªÂèñÔºåËß£Á†ÅÔºåËøôÊ†∑Â∞±ËÉΩÂæóÂà∞ÁúüÊ≠£ÁöÑÊñáÊú¨\n",
    "response = urlopen(url) \n",
    "csvfile  = csv.reader(response.read().decode('utf-8').splitlines()) \n",
    "\n",
    "# Â±ïÁ§∫ËØªÂèñÁöÑ\n",
    "for row in csvfile:\n",
    "    urlData.append(row)\n",
    "\n",
    "print(\"urlData has \" + str(len(urlData)) + \" rows and \" + str(len(urlData[0])) + \" columns.\")\n",
    "print(urlData[-1]) # Check it worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get `urlData has 11 rows and 4 columns.` and a row that looks like this: `['Bangor', '18808', '53.228', '-4.128']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Getting Organised\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low</div>\n",
    "\n",
    "Let's take the code above and modify it so that it is:\n",
    "\n",
    "1. A function that takes two arguments: a URL; and a destination filename.\n",
    "2. Implemented as a function that checks if a file exists already before downloading it again.\n",
    "\n",
    "You will find that the `os` module helps here because of the `path` function. And you will [need to Google](https://lmgtfy.app/?q=check+if+file+exists+python) how to test if a file exists. I would normally select a StackOverflow link in the results list over anything else because there will normally be an _explanation_ included of why a particular answer is a 'good one'. I also look at which answers got the most votes (not always the same as the one that was the 'accepted answer'). In this particular case, I also found [this answer](https://careerkarma.com/blog/python-check-if-file-exists/) useful.\n",
    "\n",
    "I would start by setting my inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Wikipedia-Cities.csv\n"
     ]
    }
   ],
   "source": [
    "# osÂåÖÈáåÊúâpathÂáΩÊï∞\n",
    "# os.path.joinÔºàÔºâ Êô∫ËÉΩÂú∞ËøûÊé•‰∏Ä‰∏™ÊàñÂ§ö‰∏™Ë∑ØÂæÑÁªÑ‰ª∂\n",
    "\n",
    "# out Â∞±‰ª£Ë°®ÁùÄ 'data'Êñá‰ª∂Â§π‰∏ã'Wikipedia-Cities.csv'Ëøô‰∏™Êñá‰ª∂\n",
    "\n",
    "\n",
    "import os\n",
    "url = \"https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities-simple.csv\"\n",
    "out = os.path.join('data','Wikipedia-Cities.csv') # Print `out` if you aren't sure what this has done!\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Sketching the Function\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low</div>\n",
    "\n",
    "Then I would sketch out how my function will work using comments. And the simplest thing to start with is checking whether the file has already been downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Wikipedia-Cities.csv found!\n"
     ]
    }
   ],
   "source": [
    "# Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶‰∏ãËΩΩ üòÄ\n",
    "\n",
    "# # ÂêØÁî®urlopenÂäüËÉΩ\n",
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "# get_url(src,dest)  srcÂíådest ÊòØget_urlÈáåÁöÑ‰∏§‰∏™ÂèÇÊï∞\n",
    "# get_url(url, out)  urlÂíåout ‰πüÊòØget_urlÈáåÁöÑ‰∏§‰∏™ÂèÇÊï∞\n",
    "# src ÂØπÂ∫î url    dest ÂØπÂ∫î out\n",
    "def get_url(src, dest):\n",
    "    \n",
    "    # os.path.isfile()ÔºöÂà§Êñ≠Êüê‰∏ÄÂØπË±°ÊòØÂê¶‰∏∫Êñá‰ª∂\n",
    "    # os.path.isdir()ÔºöÂà§Êñ≠Êüê‰∏ÄÂØπË±°ÊòØÂê¶‰∏∫ÁõÆÂΩï\n",
    "   \n",
    "    if os.path.isfile(dest):\n",
    "        print(f\"{dest} found!\")\n",
    "    else:\n",
    "        print(f\"{dest} *not* found!\")\n",
    "        \n",
    "get_url(url, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 Fleshing Out the Function \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Difficulty level</b>: Medium, if you really explore what's going on in the function rather than just running it and moving on.</div>\n",
    "\n",
    "I would then flesh out the code so that it downloads the file if it isn't found and then, either way, returns the *local* file path for our CSV reader to extract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Wikipedia-Cities.csv found locally!\n"
     ]
    }
   ],
   "source": [
    "# Ê£ÄÊü•Êñá‰ª∂ÊòØÂê¶‰∏ãËΩΩ üòÄ\n",
    "# Âú®Ê≤°ÊúâÊâæÂà∞Êñá‰ª∂Êó∂‰∏ãËΩΩÊñá‰ª∂\n",
    "\n",
    "def get_url(src, dest):\n",
    "    \n",
    "    # Ê£ÄÊü• destÊñá‰ª∂ÊòØÂê¶Â≠òÂú®Ôºà‰πüÂ∞±ÊòØ out ÂèàÊòØdata/Wikipedia-Cities.csvÔºâ\n",
    "    # Âê¶Âàô‰∏ãËΩΩdestÊñá‰ª∂\n",
    "    if os.path.isfile(dest):\n",
    "        print(f\"{dest} found locally!\")\n",
    "    else:\n",
    "        print(f\"{dest} not found, downloading!\")\n",
    "        \n",
    "        #¬†ÈÄöËøá urlopen Ëé∑ÂæóÊï∞ÊçÆ\n",
    "        # Â∞Ü srcÔºà‰πüÂ∞±ÊòØurlÔºâËØªÂÖ•Âêç‰∏∫'response'ÁöÑÂèòÈáè\n",
    "        # ‰ªéresponseËØªÂèñÔºåËß£Á†ÅÔºåÂæóÂà∞ÁúüÊ≠£ÁöÑÊï∞ÊçÆ\n",
    "        response = urlopen(src) \n",
    "        filedata = response.read().decode('utf-8')\n",
    "        \n",
    "        # os.path.split ÊÑè‰∏∫ÂàÜÂâ≤destÔºàdata/Wikipedia-Cities.csvÔºâ\n",
    "        # pathÂ∞±ÊòØdest ÂÄíÊï∞Á¨¨‰∏Ä‰∏™Êñá‰ª∂ ÔºàWikipedia-Cities.csvÔºâ\n",
    "        path = list(os.path.split(dest)[:-1])\n",
    "        \n",
    "        \n",
    "        # Create any missing directories in dest(ination) path\n",
    "        # -- os.path.join is the reverse of split (as you saw above)\n",
    "        # but it doesn't work with lists... so I had to google how \n",
    "        # to use the 'splat' operator! os.makedirs creates missing \n",
    "        # directories in a path automatically.\n",
    "        if len(path) >= 1 and path[0] != '':\n",
    "            os.makedirs(os.path.join(*path), exist_ok=True)\n",
    "        \n",
    "        with open(dest, 'w') as f:\n",
    "            f.write(filedata)\n",
    "            \n",
    "        print(f\"Data written to {dest}!\")\n",
    "    \n",
    "   \n",
    "    return dest\n",
    "        \n",
    "\n",
    "src = get_url(url, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>&#9888; Stop!</b> It really would be a good idea to put in the effort to make sense of how this function works. There is a lot going on here and understanding how this function works will help you to understand how to code. You should notice that we don't try to check if the data file contains any useful data! So if you download or create an empty file while testing, you won't necessarily get an error until you try to turn it into data afterwards!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Parse the CSV File\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low</div>\n",
    "\n",
    "Now we turn to the next task: parsing the file if it's a CSV. This implies that it *might* not be so that's something we should also consider!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['City', 'Population', 'Latitude', 'Longitude'],\n",
       " ['Perth', '45770', '56.39583', '-3.43333'],\n",
       " ['Armagh', '14777', '54.3499', '-6.6546'],\n",
       " ['Dundee', '147268', '56.462', '-2.9707'],\n",
       " ['Colchester', '194706', '51.88861', '0.90361'],\n",
       " ['Salisbury', '40302', '51.07', '-1.79'],\n",
       " ['Portsmouth', '205056', '50.80583', '-1.08722'],\n",
       " ['Wakefield', '325837', '53.683', '-1.499'],\n",
       " ['Bradford', '522452', '53.792', '-1.754'],\n",
       " ['Lancaster', '138375', '54.047', '-2.801'],\n",
       " ['Bangor', '18808', '53.228', '-4.128']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ÈúÄË¶ÅËß£ÊûêËØ•Êñá‰ª∂ÊòØÂê¶‰∏∫ csv (ÈÅøÂÖçÂΩ±ÂìçÂêéÁª≠Â∑•‰ΩúÔºâüçú\n",
    "\n",
    "\n",
    "#  read_csv Âíå csv.reader Âü∫Êú¨‰∏ä‰ΩúÁî®‰∏ÄÊ†∑ÔºåÂç≥\n",
    "# ‰ΩøÁî®csvÊ®°ÂùóËØªÂèñÊñá‰ª∂ÔºåËá™Âä®splitÂàÜÂâ≤ÈÄóÂè∑ÔºåÂΩ¢ÊàêÂàóË°®Êï∞ÊçÆ\n",
    "# Âè™ÊòØÔºåread_csvËØªÂèñÊñá‰ª∂Âêé‰ºö‰øùÊåÅÂéüÂßãÊï∞ÊçÆÁöÑÂàóÂêçÁß∞\n",
    "\n",
    "# src => url => websiteData ÔºàÁî±‰∏äÊâÄÂæóÔºâ\n",
    "\n",
    "import csv\n",
    "\n",
    "# ‰ΩøÁî®csvÊ®°ÂùóËØªÂèñsrcÊñá‰ª∂\n",
    "def read_csv(src):\n",
    "    \n",
    "    # ÂàóË°®csvdata ‰∏≠Â≠òÂú® ÂàóË°®csvr\n",
    "    # ÂàóË°®csvr ÊòØfÁöÑcsvÊ†ºÂºè\n",
    "    # f Âç≥ Ôºà'websiteData','r')\n",
    "    csvdata = []\n",
    "    with open(src, 'r') as f:\n",
    "        csvr = csv.reader(f)\n",
    "        \n",
    "        # 'r' Âú®ÂàóË°®csvr\n",
    "        # ÈÇ£‰πàÂàóË°®csvdata ‰πü‰ºöÂá∫Áé∞ 'r'\n",
    "        for r in csvr:\n",
    "            csvdata.append(r)\n",
    "    \n",
    "    # Return list of lists\n",
    "    return csvdata\n",
    "\n",
    "read_csv(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get:\n",
    "\n",
    "```\n",
    "[['City', 'Population', 'Latitude', 'Longitude'],\n",
    " ['Perth', '45770', '56.39583', '-3.43333'],\n",
    " ['Armagh', '14777', '54.3499', '-6.6546'],\n",
    " ['Dundee', '147268', '56.462', '-2.9707'],\n",
    " ['Colchester', '194706', '51.88861', '0.90361'],\n",
    " ['Salisbury', '40302', '51.07', '-1.79'],\n",
    " ['Portsmouth', '205056', '50.80583', '-1.08722'],\n",
    " ['Wakefield', '325837', '53.683', '-1.499'],\n",
    " ['Bradford', '522452', '53.792', '-1.754'],\n",
    " ['Lancaster', '138375', '54.047', '-2.801'],\n",
    " ['Bangor', '18808', '53.228', '-4.128']]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3: Convert the CSV into a DoL\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Difficulty level</b>: Medium.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can focus on converting the CSV data to a dictionary-of-lists! We're going to start with the *same* function name but expand what the function *does*. This kind of *iteration* is common in software development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'City': ['Perth',\n",
       "  'Armagh',\n",
       "  'Dundee',\n",
       "  'Colchester',\n",
       "  'Salisbury',\n",
       "  'Portsmouth',\n",
       "  'Wakefield',\n",
       "  'Bradford',\n",
       "  'Lancaster',\n",
       "  'Bangor'],\n",
       " 'Population': ['45770',\n",
       "  '14777',\n",
       "  '147268',\n",
       "  '194706',\n",
       "  '40302',\n",
       "  '205056',\n",
       "  '325837',\n",
       "  '522452',\n",
       "  '138375',\n",
       "  '18808'],\n",
       " 'Latitude': ['56.39583',\n",
       "  '54.3499',\n",
       "  '56.462',\n",
       "  '51.88861',\n",
       "  '51.07',\n",
       "  '50.80583',\n",
       "  '53.683',\n",
       "  '53.792',\n",
       "  '54.047',\n",
       "  '53.228'],\n",
       " 'Longitude': ['-3.43333',\n",
       "  '-6.6546',\n",
       "  '-2.9707',\n",
       "  '0.90361',\n",
       "  '-1.79',\n",
       "  '-1.08722',\n",
       "  '-1.499',\n",
       "  '-1.754',\n",
       "  '-2.801',\n",
       "  '-4.128']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‰ΩøÁî®read_csv/ csv.readerËØªÂèñÊñá‰ª∂ÔºåËá™Âä®splitÂàÜÂâ≤ÈÄóÂè∑ÔºåÂΩ¢ÊàêÂàóË°®Êï∞ÊçÆ\n",
    "# Ëé∑Âèñ‰∏ÄË°å‰∏≠ÁöÑÊüê‰∏ÄÂàóÊï∞ÊçÆÔºåÂè™ËÉΩÈÄöËøáÂàóË°®ÁöÑÁ¥¢ÂºïÔºå‰∏çÊñπ‰æø\n",
    "\n",
    "# Âõ†Ê≠§ÔºåËøô‰∏ÄÊ≠•Êääcsv data ËΩ¨Êç¢‰∏∫ dictionary-of-list üòä\n",
    "\n",
    "def read_csv(src):\n",
    "    \n",
    "    csvdata = {} # ‰∏Ä‰∏™Á©∫ÁöÑ dictionary-of-lists\n",
    "    \n",
    "    with open(src, 'r') as f:\n",
    "        csvr = csv.reader(f)\n",
    "        \n",
    "        #¬†ËØªÂÖ• columnÂàó ÂêçÁß∞\n",
    "        # ÂàùÂßãÂåñ dictionary-of-lists\n",
    "        csvcols = next(csvr) \n",
    "        for c in csvcols:\n",
    "            csvdata[c] = []\n",
    "        \n",
    "        # Notice this code is still the same, \n",
    "        # we just used next(csvr) to get the \n",
    "        # header row first!\n",
    "        for r in csvr: \n",
    "            # Although you can often assume that the order \n",
    "            # of the keys is the same, Python doesn't \n",
    "            #¬†guarantee it; this way we will always make\n",
    "            # the correct assignment.\n",
    "            for idx, c in enumerate(csvcols):\n",
    "                csvdata[c].append(r[idx])\n",
    "    \n",
    "    # ËΩ¨Êç¢ÂÆåÊàê ËøîÂõû dictionary-of-lists\n",
    "    return csvdata\n",
    "\n",
    "read_csv(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get something that starts:\n",
    "```\n",
    "{'City': ['Perth',\n",
    "  'Armagh',\n",
    "  'Dundee',\n",
    "  'Colchester',\n",
    "  'Salisbury',\n",
    "  'Portsmouth',\n",
    "  'Wakefield',\n",
    "  'Bradford',\n",
    "  'Lancaster',\n",
    "  'Bangor'],\n",
    " 'Population': ['45770',\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.4: Adding Docstring\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low</div>\n",
    "\n",
    "We've assumed that the first row of our data set is always a _header_ (i.e. list of column names). If it's not then this code is going to have problems. A _robust_ function would allow us to specify column names, skip rows, etc. when we create the data structure, but let's not get caught up in that level of detail. Notice that I've also, for the first time:\n",
    "\n",
    "1. Used the docstring support offered by Python. You'll be able to use `help(...)` and get back the docstring help!\n",
    "2. Provided hints to Python about the expected input and output data types. This can help to ensure consistency and is also critical in testing / continuous integration when working with others on a codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv file ËΩ¨Êç¢+ÊûÑÂª∫ DOLÊï∞ÊçÆÁªìÊûÑÊó∂\n",
    "# È¢ÑÊµã„ÄÅËØÜÂà´Êï∞ÊçÆÁ¨¨‰∏ÄË°å\n",
    "# Â¶ÇÊûúÁ¨¨‰∏ÄË°åÊòØÂàóÂêçÁß∞Ôºå Ëá™Âä®ÂàõÂª∫‰∏∫ DOLÂΩ¢ÂºèÁöÑÂàóÂêçÁß∞ü•ß\n",
    "# Â¶ÇÊûúÁ¨¨‰∏ÄË°å‰∏çÊòØÔºåÂàôÊâãÂä®ÊåáÂÆöÊüê‰∏ÄË°å\n",
    "\n",
    "def read_csv(src:str) -> dict:\n",
    "    \"\"\"\n",
    "    Converts a CSV file to a dictionary-of-lists (dol),\n",
    "    using the first row to create column names.\n",
    "    \n",
    "    :param src: local csv file\n",
    "    :returns: DOL\n",
    "    \"\"\"\n",
    "    csvdata = {} # ‰∏Ä‰∏™Á©∫ÁöÑ dictionary-of-lists\n",
    "    \n",
    "    with open(src, 'r') as f:\n",
    "        csvr = csv.reader(f)\n",
    "        \n",
    "        #¬†ËØªÂÖ• columnÂàó ÂêçÁß∞\n",
    "        # ÂàùÂßãÂåñ dictionary-of-lists\n",
    "        csvcols = next(csvr) \n",
    "        for c in csvcols:\n",
    "            csvdata[c] = []\n",
    "        \n",
    "        # Notice this code is still the same, \n",
    "        # we just used next(csvr) to get the \n",
    "        # header row first!\n",
    "        for r in csvr: \n",
    "            # Although you can often assume that the order \n",
    "            # of the keys is the same, Python doesn't \n",
    "            #¬†guarantee it; this way we will always make\n",
    "            # the correct assignment.\n",
    "            for idx, c in enumerate(csvcols):\n",
    "                csvdata[c].append(r[idx])\n",
    "    \n",
    "    # ËΩ¨Êç¢ÂÆåÊàê ËøîÂõû dictionary of lists\n",
    "    return csvdata\n",
    "\n",
    "ds = read_csv(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module __main__:\n",
      "\n",
      "read_csv(src: str) -> dict\n",
      "    Converts a CSV file to a dictionary-of-lists (dol),\n",
      "    using the first row to create column names.\n",
      "    \n",
      "    :param src: local csv file\n",
      "    :returns: DOL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are: City, Population, Latitude, Longitude\n",
      "First two cities are: ['Perth', 'Armagh']\n",
      "First two populations are: ['45770', '14777']\n",
      "First two latitudes are: ['56.39583', '54.3499']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns are: \" + \", \".join(ds.keys()))\n",
    "print(f\"First two cities are: {ds['City'][:2]}\")\n",
    "print(f\"First two populations are: {ds['Population'][:2]}\")\n",
    "print(f\"First two latitudes are: {ds['Latitude'][:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer should look like:\n",
    "```\n",
    "Columns are: City, Population, Latitude, Longitude\n",
    "First two cities are: ['Perth', 'Armagh']\n",
    "First two populations are: ['45770', '14777']\n",
    "First two latitudes are: ['56.39583', '54.3499']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5: Fixing Data Types\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Difficulty level</b>: Medium.</div>\n",
    "\n",
    "If you look closely at the above, you'll see that *everything* is a string, including the latitudes, longitudes, and populations, which are clearly numeric data types. Here's a 'simple' way to specify a `dtype` list to hold the _data type_ for each column. I'm also going to introduce you the `zip` function here as it has many uses with geographic data (especially converting lat/long to points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.1 Demonstrating Zip\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column         City should be type: str\n",
      "Column   Population should be type: int\n",
      "Column     Latitude should be type: float\n",
      "Column    Longitude should be type: float\n"
     ]
    }
   ],
   "source": [
    "# dtype ÂèØ‰ª•‰øùÊåÅÊØè‰∏ÄÂàóÁöÑÊï∞ÊçÆÁ±ªÂûã üçç\n",
    "# zipÂáΩÊï∞ ÁªèÂ∏∏Áî®‰∫éÂú∞ÁêÜÊï∞ÊçÆ ÔºàÊØîÂ¶ÇÔºåÂèØ‰ª•ÊääÁªèÁ∫¨Â∫¶ËΩ¨Êç¢‰∏∫\"ÁÇπ\"Ôºâ\n",
    "\n",
    "# strÂ≠óÁ¨¶‰∏≤ÔºåintÊï¥Êï∞ÔºåfloatÂ∞èÊï∞\n",
    "cols  = ['City', 'Population', 'Latitude', 'Longitude'] # <- Column name\n",
    "dtype = [str, int, float, float]                        # <- Column data type\n",
    "\n",
    "\n",
    "# colsÔºådtype‰∏§‰∏™ÂàóË°® ÂéãÁº©Âà∞Âêå‰∏Ä‰∏™Ëø≠‰ª£Âô® zip\n",
    "for col in zip(cols, dtype):\n",
    "    colname = col[0]\n",
    "    coltype = col[1]\n",
    "    \n",
    "\n",
    "    # - `>12` ÊÑèÂë≥ÁùÄÂêëÂè≥ÂØπÂÖ∂ÔºåÁ©∫Ê†º‰∏çË∂ÖËøá12Â≠óÁ¨¶\n",
    "    print(f\"Column {colname:>12} should be type: {coltype.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.2 A Function to Convert Data Types\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low, as I've provided a function.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÂéüÂßãÊï∞ÊçÆ ËΩ¨Êç¢‰∏∫ ÈÄÇÂΩìÁöÑÊï∞ÊçÆ\n",
    "\n",
    "# ‰∏ãÈù¢ÊòØÂú®ËÆ≤ËΩ¨Êç¢ÁöÑÂéüÁêÜ œÜ(‚óé„É≠‚óé;)œÜ\n",
    "\n",
    "# type: 'column data' (cdata) -> 'column type' (ctype)\n",
    "\n",
    "def to_type(cdata, ctype):\n",
    "    # If a string\n",
    "    if isinstance(cdata, str):\n",
    "        try:\n",
    "            if ctype==bool:\n",
    "                return cdata==True\n",
    "            else:\n",
    "                return ctype(cdata)\n",
    "        except TypeError:\n",
    "            return cdata\n",
    "    \n",
    "    # Not a string (assume list)\n",
    "    else: \n",
    "        fdata = []\n",
    "        for c in cdata:\n",
    "            try:\n",
    "                if ctype==bool:\n",
    "                    fdata.append( c=='True' )\n",
    "                else:\n",
    "                    fdata.append( ctype(c) )\n",
    "            except:\n",
    "                fdata.append( c )\n",
    "        return fdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'City': ['Perth', 'Armagh', 'Dundee', 'Colchester', 'Salisbury', 'Portsmouth', 'Wakefield', 'Bradford', 'Lancaster', 'Bangor'], 'Population': [45770, 14777, 147268, 194706, 40302, 205056, 325837, 522452, 138375, 18808], 'Latitude': [56.39583, 54.3499, 56.462, 51.88861, 51.07, 50.80583, 53.683, 53.792, 54.047, 53.228], 'Longitude': [-3.43333, -6.6546, -2.9707, 0.90361, -1.79, -1.08722, -1.499, -1.754, -2.801, -4.128]}\n"
     ]
    }
   ],
   "source": [
    "# ds = read_csv(src) ÔºåÂ∞±ÊòØcsv file ËΩ¨Êç¢‰∏∫ DOL ÁöÑÁªìÊûú\n",
    "# Á†Å10 ÁªôÊØè‰∏ÄÂàóÊï∞ÊçÆÂàÜ‰∫ÜÁ±ªÂûã\n",
    "# ds2ÊòØÊ†πÊçÆ Á†Å10ÁöÑÂàÜÁ±ªÔºåÂØπdsÊï∞ÊçÆÊØè‰∏ÄÂàóËøõË°åÂàÜÁ±ª\n",
    "\n",
    "# dsÊòØÊï∞ÊçÆ['45770']  ds2Âè™ÊòØÁ±ªÂûã[45770]\n",
    "\n",
    "ds2 = {}\n",
    "for col in zip(cols, dtype):\n",
    "    colname = col[0]\n",
    "    coltype = col[1]\n",
    "    ds2[ colname ] = to_type( ds[colname], coltype )\n",
    "\n",
    "print(ds2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the output here to the output from `ds` up above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are: City, Population, Latitude, Longitude\n",
      "First two cities are: ['Perth', 'Armagh']\n",
      "First two populations are: [45770, 14777]\n",
      "First two latitudes are: [56.39583, 54.3499]\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns are: \" + \", \".join(ds2.keys()))\n",
    "print(f\"First two cities are: {ds2['City'][:2]}\")\n",
    "print(f\"First two populations are: {ds2['Population'][:2]}\")\n",
    "print(f\"First two latitudes are: {ds2['Latitude'][:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the followg:\n",
    "```\n",
    "Columns are: City, Population, Latitude, Longitude\n",
    "First two cities are: ['Perth', 'Armagh']\n",
    "First two populations are: [45770, 14777]\n",
    "First two latitudes are: [56.39583, 54.3499]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.6: Checking Basic Functionality\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Difficulty level</b>: Medium</div>\n",
    "\n",
    "Now that we've got our data structure all set up correctly (appropriate names, data types, etc.) let's see if it works by testing out some of our previous operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average population is 165,335.10\n",
      "Westernmost city is Armagh\n",
      "Northernmost city is Dundee\n",
      "Southernmost city is Portsmouth\n"
     ]
    }
   ],
   "source": [
    "# Âà©Áî® numpyÂáΩÊï∞Êü•Êâæ‰Ωç‰∫é ‰∏úË•øÂçóÂåóÊúÄÊûÅÁ´ØÁöÑÂüéÂ∏Ç üåèüåπ(ÔΩ°ÔΩ•‚àÄÔΩ•)ÔæâÔæû\n",
    "\n",
    "# ÂÖ¨ÂºèÔºö {ds2['City'][np.where(ds2['Longitude']==np.min(ds2['Longitude']))[0][0]]}\n",
    "# ds2ÔºöDOLÂΩ¢ÂºèÁöÑÊï∞ÊçÆ\n",
    "# min'Longitude'ÊúÄË•øÁ´Ø  max'Longitude'ÊúÄ‰∏úÁ´Ø\n",
    "# min'Latitude'ÊúÄÂçóÁ´Ø  max'Latitude'ÊúÄÂåóÁ´Ø\n",
    "\n",
    "\n",
    "import numpy as np # We'll need this to apply functions to lists easily\n",
    "\n",
    "print(f\"Average population is {np.mean(ds2['Population']):,.2f}\")\n",
    "print(f\"Westernmost city is {ds2['City'][np.where(ds2['Longitude']==np.min(ds2['Longitude']))[0][0]]}\")\n",
    "print(f\"Northernmost city is {ds2['City'][np.where(ds2['Latitude']==np.max(ds2['Latitude']))[0][0]]}\")\n",
    "print(f\"Southernmost city is {ds2['City'][np.where(ds2['Latitude']==np.min(ds2['Latitude']))[0][0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following:\n",
    "\n",
    "```\n",
    "Average population is 165,335.10\n",
    "Westernmost city is Armagh\n",
    "Northernmost city is Dundee\n",
    "Southernmost city is Portsmouth\n",
    "```\n",
    "\n",
    "There are a few things to understand here:\n",
    "\n",
    "1. Where we want to find something else in the data *based on that value* then things get a little more complex: we use `np.min` to find the smallest value in the data, but we don't know *where* in the list that value actually *was* so we use `np.where` to find out which indexes match the minimum value. In this data set it's easy because there's one, and only one value that matches. But you'd need to do some clever thinking about how to handle ties.\n",
    "2. `np.where` returns a complex data structure (list-of-lists, essentially) so we need to pull the value we need out of that data in order to actually find the list index we need and look up the `City` name associated with, for example, the minium value in the data. That bit (`[0][0]`) is a bit clunky, but right now we're not too worried about it.\n",
    "\n",
    "**Notice** that we do *all* of this without using a `for` loop or variables to keep track of what we've found... You *could* also use a `for` loop to answer each of these questions (see the example below), but hopefully you see what the way we've used above is more *elegant* (it's also faster):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum longitude is -6.6546\n",
      "Westernmost city is Armagh\n"
     ]
    }
   ],
   "source": [
    "# ‰ª•‰∏ãÊòØ‰ΩøÁî®forÂæ™ÁéØÊü•Êâæ‰ø°ÊÅØ\n",
    "# ‰ΩÜÁ†Å21ÁöÑÊñπÂºèÊõ¥Êô∫ÊÖß\n",
    "\n",
    "min_long = 180\n",
    "min_idx  = -1\n",
    "\n",
    "for l in ds2['Longitude']:\n",
    "    if l < min_long: min_long = l\n",
    "print(f\"Minimum longitude is {min_long}\")\n",
    "\n",
    "for idx, l2 in enumerate(ds2['Longitude']):\n",
    "    if l2==min_long:\n",
    "        min_idx = idx\n",
    "        break\n",
    "\n",
    "print(f\"Westernmost city is {ds2['City'][min_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##¬†Task 3. Was it Worth It?\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low</div>\n",
    "\n",
    "At this point it's worth asking: was all this *worth* it? Let's see! \n",
    "\n",
    "The best way to test is to use a *different* data set and see if we've solved the 'hard-coding' problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Wikipedia-Cities-full.csv found locally!\n"
     ]
    }
   ],
   "source": [
    "# ‰ΩøÁî®‰∏çÂêåÊï∞ÊçÆÈõÜ Ê£ÄÈ™å‰ª£Á†Å\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities.csv\"\n",
    "out = os.path.join('data','Wikipedia-Cities-full.csv')\n",
    "\n",
    "cols  = ['City', 'Population', 'Latitude', 'Longitude']\n",
    "dtype = [str, int, float, float]\n",
    "\n",
    "untyped_dol = read_csv(get_url(url, out))\n",
    "\n",
    "typed_dol = {}\n",
    "for col in zip(cols, dtype):\n",
    "    colname = col[0]\n",
    "    coltype = col[1]\n",
    "    typed_dol[ colname ] = to_type(untyped_dol[colname], coltype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average population is 202,283.36\n",
      "Westernmost city is Derry\n",
      "Northernmost city is Inverness, Inerness, Inbhir Nis\n",
      "Southernmost city is Truro\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average population is {np.mean(typed_dol['Population']):,.2f}\")\n",
    "print(f\"Westernmost city is {typed_dol['City'][np.where(typed_dol['Longitude']==np.min(typed_dol['Longitude']))[0][0]]}\")\n",
    "print(f\"Northernmost city is {typed_dol['City'][np.where(typed_dol['Latitude']==np.max(typed_dol['Latitude']))[0][0]]}\")\n",
    "print(f\"Southernmost city is {typed_dol['City'][np.where(typed_dol['Latitude']==np.min(typed_dol['Latitude']))[0][0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get:\n",
    "\n",
    "```\n",
    "Average population is 202,283.36\n",
    "Westernmost city is Derry\n",
    "Northernmost city is Inverness, Inerness, Inbhir Nis\n",
    "Southernmost city is Truro\n",
    "```\n",
    "\n",
    "So we used all the same code as for the subset of the data but changed *nothing*. And this is even though the column order changed (print out the first row of each file if you don't believe me) *and* the number of columns changed *and* our city column now contains commas! So what this has given us is a much more flexible way not only to *access* the data, but also to *work* with it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 4. More Functions!\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Difficulty level</b>: Medium</div>\n",
    "\n",
    "Here is the skeleton of a function to replace the `np.where(column==np.[min|max|...](column))[0][0]` code. There are a few ways to do this: \n",
    "\n",
    "1. You could use if/else/elif and do different things based on testing against the specified string\n",
    "2. You could try to find a function in `numpy` that matches the specified string\n",
    "3. You could try to `eval` the code, but I really wouldn't recommend this for security reasons\n",
    "\n",
    "I have gone with a combination of 1 and 2, but you will need to really read the code to understand how it works. I've left the docstring for you to complete. This isn't the best function since it makes some assumptions about the types of data that it might be passed to the function: this is where *Object-Oriented Programming* could come to the rescue! If we had different column *types* (e.g. String, Float, Int) then we could have different *versions* of `find_val` that performed the same *function* (find a value) but did this completely differently depending on the data. This is what *methods* do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "52.801835\n"
     ]
    }
   ],
   "source": [
    "# Áî®Êõ¥ÁÆÄ‰æøÊñπÂºè ËÆ°ÁÆó ÊåëÈÄâ Êï∞ÊçÆ \n",
    "# ‰ΩøÁî® numpy ÁöÑÂäüËÉΩ find_val (ÊÑè‰∏∫ find a valueÔºâ\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def find_val(col:list, val:str):\n",
    "    \"\"\"\n",
    "    :param col: a list of numeric values\n",
    "    :param val: what kind of value to search for (in the sense of min, max, median, etc.)\n",
    "    :returns: the result of the search (e.g. the minimum value in the list as located by the numpy function)\n",
    "    \"\"\"\n",
    "    if val in dir(np) and callable(getattr(np, val)):\n",
    "        func = getattr(np, val) # <--- What does this do???\n",
    "        if val in ['min','max']:\n",
    "            return np.where(col==func(col))[0][0]\n",
    "        else:\n",
    "            return func(col)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "print(find_val(typed_dol['Latitude'], 'min'))\n",
    "print(find_val(typed_dol['Latitude'], 'median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average population is 202,283.36\n",
      "Westernmost city is Derry\n",
      "Northernmost city is Inverness, Inerness, Inbhir Nis\n",
      "Southernmost city is Truro\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average population is {find_val(typed_dol['Population'],'mean'):,.2f}\")\n",
    "print(f\"Westernmost city is {typed_dol['City'][find_val(typed_dol['Longitude'],'min')]}\")\n",
    "print(f\"Northernmost city is {typed_dol['City'][find_val(typed_dol['Latitude'],'max')]}\")\n",
    "print(f\"Southernmost city is {typed_dol['City'][find_val(typed_dol['Latitude'],'min')]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have streaminlined the code still further and implemented a fairly generic 'helper' function that uses `numpy` to perform calculations on a column of data (assuming it's numeric). We could, of course, extend this further, to handle strings and other data types, but we're going to see a *better* way to do all of this *next* week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5. Creating a Package from Functions\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"><b>Difficulty level</b>: Hard.</div>\n",
    "\n",
    "Below is code to create a package called `dtools` (i.e. data tools) by converting the notebook into a Python script file called `__init__.py` that sits in the `dtools` directory. This is the first step to creating a package from code that is *already* working in a Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.1 Create a Directory\n",
    "\n",
    "When creating your own package, everything goes into a directory whose name is the name of the package. In other words, if you wanted to create a package called `my_stuff` then you'd need to *first* create a directory called `my_staff` in the *current working directory* (i.e. wherever you are keeping your Notbooks).\n",
    "\n",
    "We can create the directory using `mkdir` (the `!` means 'run this [Linux] command'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÂàõÂª∫ Âêç‰∏∫dtoolsÁöÑÂäüËÉΩÂåÖÔºåÂ∞ÜÂÖ∂ÊîæÂú®Ëá™Â∑±ÁöÑÁõÆÂΩï fsds_JÈáå ü¶Å\n",
    "\n",
    "!mkdir -p 'dtools'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.2 Create \\_\\_init\\_\\_.py\n",
    "\n",
    "More complex packages will have lots of stuff going on inside their 'root' directory, but we're keeping it simple and only need to create and fill in *one* file inside the `dtools` directory: `__init__.py`. This is a convention.\n",
    "\n",
    "We can create this file two ways: \n",
    "\n",
    "1. By creating an empty file with that name in `dtools` (e.g. `!touch dtools/__init__.py` would work!)\n",
    "2. By converting *this* entire notebook to a Python script and then removing all the stuff that *is not* a function that we need to keep.\n",
    "\n",
    "The 'hybrid' way, which I'm going to suggest you use so you get some more experience, would be to convert this notebook to a Python script file, open it, and then copy the functions out into `__init__.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Practical-04-Objects-Answers.ipynb to python\n",
      "[NbConvertApp] Writing 40040 bytes to dtools/notebook.py\n"
     ]
    }
   ],
   "source": [
    "# Âú®dtoolsÁõÆÂΩï‰∏≠ÂàõÂª∫Âπ∂Â°´ÂÖÖ‰∏Ä‰∏™Êñá‰ª∂:_init_.py\n",
    "# _init_.py ÂåÖÂê´‰∫Ü‰∏ãÈù¢ÂõõË°åÁöÑÂäüËÉΩ (url csv type val)\n",
    "\n",
    "# _init_.py Âú®‰∏ÄÂÆöÁ®ãÂ∫¶‰∏äÁÆÄÂåñ‰∫ÜÊï∞ÊçÆËØªÂèñ„ÄÅÈÄâÊã©„ÄÅÊèêÂèñÔºüÔºü\n",
    "\n",
    "\n",
    "!touch dtools/__init__.py\n",
    "# Comment out so we don't automatically re-run this code every time\n",
    "!jupyter nbconvert --ClearOutputPreprocessor.enabled=True \\\n",
    "    --to python --output=dtools/notebook.py \\\n",
    "    Practical-04-Objects-Answers.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 5.3 Extract Code to Init\n",
    "\n",
    "You now need to open `notebook.py` and find+copy the following functions into `__init__.py`:\n",
    "\n",
    "1. `get_url`\n",
    "2. `read_csv` \n",
    "3. `to_type` \n",
    "4. `find_val`\n",
    "\n",
    "And don't forget to find all the `import` statements (including `from x import y`) and copy those as well!\n",
    "\n",
    "You should then be able to run the code below and can always compare it to my version [on GitHub](https://github.com/jreades/fsds/blob/master/practicals/dtools/__init__.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.6 Test\n",
    "\n",
    "The next two lines of code allow you to repeatedly edit an imported package without having to restart the entire Python notebook. So whenever Jupyter sees a change to `dtools/__init__.py` it will reload the package and update the code without you having to do anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# ‰ª•‰∏ãÊîØÊåÅÈáçÂ§çÁºñËæëÂäüËÉΩÂåÖ\n",
    "# dtools/_init_.py ÊúâÊîπÂä®Êó∂ÔºåJupyterËá™Âä®Âä†ËΩΩ\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.1 Import\n",
    "\n",
    "And now we should be able to import the package and start using the functions that we defined..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_csv in module dtools:\n",
      "\n",
      "read_csv(src: str) -> dict\n",
      "    Converts a CSV file to a dictionary-of-lists (dol),\n",
      "    using the first row to create column names.\n",
      "    \n",
      "    :param src: a local CSV file\n",
      "    :returns: a dictionary-of-lists\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Âä†ËΩΩ dtools ÂäüËÉΩÂåÖÔºåÂèäÂÖ∂ read csvÂäüËÉΩ\n",
    "\n",
    "import dtools\n",
    "help(dtools.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.2 Use Read_CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found data/crime-sample.csv locally!\n"
     ]
    }
   ],
   "source": [
    "url = 'https://github.com/jreades/fsds/raw/master/data/2019-sample-crime.csv'\n",
    "out = os.path.join('data','crime-sample.csv')\n",
    "\n",
    "ds = dtools.read_csv(dtools.get_url(url, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds has 11 columns, these are: ID, Case Number, Date, Primary Type, Description, Location Description, Arrest, Domestic, Year, Latitude, Longitude\n",
      "There are 100 rows of data\n"
     ]
    }
   ],
   "source": [
    "print(f\"ds has {len(ds.keys())} columns, these are: \" + \", \".join(ds.keys()))\n",
    "print(f\"There are {len(ds['ID'])} rows of data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.3 Use To_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols  = ['Latitude', 'Longitude'] \n",
    "dtype = [float, float]\n",
    "\n",
    "typed_ds = {}\n",
    "for col in zip(cols, dtype): #¬†<- This only copies these two columns to typed_ds\n",
    "    colname = col[0]\n",
    "    coltype = col[1]\n",
    "    typed_ds[ colname ] = dtools.to_type(ds[colname], coltype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.4 Use Find_Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_val(typed_ds['Latitude'], 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JC227392\n",
      "DOMESTIC BATTERY SIMPLE\n"
     ]
    }
   ],
   "source": [
    "print(ds['Case Number'][idx])\n",
    "print(ds['Description'][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6. Brain Teaser\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"><b>Difficulty level</b>: &#129327;.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for something completely different!\n",
    "\n",
    "We want to create a set of 'ideal shapes' with methods allowing us to derive various properties of that shape:\n",
    "\n",
    "- Diameter: which we'll define as the longest line that can be drawn across the inside of the shape.\n",
    "- Volume: the total volume of the shape.\n",
    "- Surface Area: the total outside area of the shape.\n",
    "\n",
    "We will create all of these shape classes in the notebook so that we know they work and then will move them to an external package file so that they can be imported and re-used easily in other notebooks.\n",
    "\n",
    "We're also going to make use of a few features of Python:\n",
    "\n",
    "- You can access the class name of an instance using: `self.__class__.__name__`. And here's one key point: `self` refers to the instance, not to the class... we'll see why this matters.\n",
    "- You can raise your own exceptions easily if you don't want to implement a particular method yet.\n",
    "- You can have an 'abstract' base class that does nothing except provide a template for the 'real' classes so that they can be used interchangeably.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.1 Abstract Base Class\n",
    "\n",
    "This class appears to do very little, but there are two things to notice:\n",
    "\n",
    "1. It provides a constructor (`__init__`) that sets the `shape_type` to the name of the class automatically (so a `square` object has `shape_type='Square'`) and it stores the critical dimension of the shape in `self.dim`.\n",
    "2. It provides methods (which only raise exceptions) that will allow one shape to be used in the place of any other shape that inherits from `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‰ΩøÁî® _init_ ÁªòÂà∂ÂõæÂΩ¢ üéÇüçÆ\n",
    "# Áªô‰∫à _init_ ‰∏Ä‰∫õÊï∞Â≠¶ÂÖ¨ÂºèÁöÑÂäüËÉΩ\n",
    "\n",
    "from math import pi\n",
    "\n",
    "# Base class shape\n",
    "class shape(object): # Inherit from base class \n",
    "    def __init__(self, dimension:float=None):\n",
    "        self.shape_type = self.__class__.__name__.capitalize()\n",
    "        self.dim = dimension\n",
    "        return\n",
    "    \n",
    "    def diameter(self):\n",
    "        raise Exception(\"Unimplmented method error.\")\n",
    "    \n",
    "    def volume(self):\n",
    "        raise Exception(\"Unimplmented method error.\")\n",
    "    \n",
    "    def surface(self):\n",
    "        raise Exception(\"Unimplmented method error.\")\n",
    "        \n",
    "    def type(self):\n",
    "        return(self.shape_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.2 Cube\n",
    "\n",
    "Implements a cube:\n",
    "\n",
    "1. The diameter of the cube is given by the Pythagorean formula for the length of the hypotenuse in 3D between opposing corners: $\\sqrt{d^{2} + d^{2} + d^{2}}$ which we can reduce to $\\sqrt{3 d^{2}}$.\n",
    "2. A cube's volume is given by $d^{3}$.\n",
    "3. A cube's surface area will be the sum of its six faces: $6d^{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÁªòÂà∂Á´ãÊñπ‰Ωì\n",
    "# Âü∫‰∫é‰∏äÈù¢‰∏âÊù°ÂÖ¨ÂºèÔºåÊ†πÊçÆÂçäÂæÑdim ÂèØ‰ª•ËÆ°ÁÆócubeÁöÑ Áõ¥ÂæÑdiameter ‰ΩìÁßØvolume Ë°®Èù¢ÁßØsurface\n",
    "\n",
    "# Cube class\n",
    "class cube(shape): # Inherit from shape \n",
    "    def __init__(self, dim:float):\n",
    "        super().__init__(dim)\n",
    "        return\n",
    "    \n",
    "    def diameter(self):\n",
    "        return (3 * self.dim**2)**(1/2)\n",
    "    \n",
    "    def volume(self):\n",
    "        return self.dim**3\n",
    "    \n",
    "    def surface(self):\n",
    "        return 6*(self.dim**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.3 Sphere\n",
    "\n",
    "Implements a sphere:\n",
    "\n",
    "1. The diameter is twice the critical dimension (radius): $2d$. \n",
    "2. The volume is $\\frac{4}{3} \\pi r^{3}$.\n",
    "3. The surface area will be $4 \\pi r^{2}$.\n",
    "\n",
    "If we were writing something more general, we'd probably have spheres as a special case of an ellipsoid!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÁªòÂà∂ÁêÉ‰Ωì\n",
    "# Âü∫‰∫é‰∏äÈù¢‰∏âÊù°ÂÖ¨ÂºèÔºåÊ†πÊçÆÂçäÂæÑdim ÂèØ‰ª•ËÆ°ÁÆósphereÁöÑ Áõ¥ÂæÑdiameter ‰ΩìÁßØvolume Ë°®Èù¢ÁßØsurface\n",
    "\n",
    "# Sphere\n",
    "class sphere(shape): # Inherit from shape \n",
    "    def __init__(self, dim:float):\n",
    "        super().__init__(dim)\n",
    "        return\n",
    "    \n",
    "    def diameter(self):\n",
    "        return 2 * self.dim\n",
    "    \n",
    "    def volume(self):\n",
    "        return (4/3) * pi * (self.dim**3)\n",
    "    \n",
    "    def surface(self):\n",
    "        return 4 * pi * (self.dim**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.4 Regular Pyramid\n",
    "\n",
    "We're taking this to be a regular pyramid where all sides are equal: \n",
    "\n",
    "1. The diameter is a line drawn across the base between opposing corners of the base so it's just $\\sqrt{d^{2} + d^{2}}$.\n",
    "2. The volume is given by $V¬†=¬†b¬†*¬†h¬†/¬†3$ (where $b$ is the area of the base, which in this case becomes $d^{2} * h/3$).\n",
    "3. The surface area will be the base + 4 equilateral triangles: $d^{2} + 4 (d^{2}\\sqrt{3}/4)$ which we can reduce to $d^{2} + d^{2}\\sqrt{3}$\n",
    "\n",
    "But this requires a _height_ method that is specific to pyramids:\n",
    "\n",
    "4. The height is taken from the centre of the pyramid (which will be half the length of the hypotenuse for two edges): $l = \\sqrt{d{^2} + d^{2}}$ and the long side ($d$ again) which gives us $\\sqrt{l/2 + d^{2}}$.\n",
    "\n",
    "Note that this has a class variable called `has_mummies` since Egyptian regular pyramids are plagued by them! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular pyramid Ê≠£ËßíÈî•‰Ωì\n",
    "# ÂÖ¨Âºè‰∏≠ÁöÑ l Â∞±ÊòØ Áõ¥ÂæÑdiameter\n",
    "\n",
    "\n",
    "# Pyramid class\n",
    "class pyramid(shape): # Inherit from shape\n",
    "    \n",
    "    has_mummies = True # This is for *all* regular pyramids\n",
    "    \n",
    "    def __init__(self, dim:float):\n",
    "        super().__init__(dim)\n",
    "        self.shape_type = 'Regular Pyramid'\n",
    "        return\n",
    "    \n",
    "    def diameter(self):\n",
    "        return (self.dim**2 + self.dim**2)**(1/2)\n",
    "    \n",
    "    def height(self):\n",
    "        return (self.diameter()/2 + self.dim**2)**(1/2)\n",
    "    \n",
    "    def volume(self):\n",
    "        return self.dim**2 * self.height() / 3\n",
    "    \n",
    "    def surface(self):\n",
    "        return self.dim**2 + self.dim**2 * 3**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.5 Triangular Pyramid\n",
    "\n",
    "We want triangular pyramid to inherit from regular pyramid, and all sides are equal so it's an _equilateral_ triangular pyramid. However, this is kind of a judgement call since there's very little shared between the two types of pyramid and it's arguable whether this one is actually simpler and should therefore be the parent class...\n",
    "\n",
    "Anyway, the calculations are:\n",
    "\n",
    "1. The diameter (longest line through the shape) will just be the edge: $d$.\n",
    "2. The volume $V = b * h / 3$ where $b$ is the area of an equilateral triangle.\n",
    "3. The surface area will be $4b$ where $b$ is the area of an equilateral triangle.\n",
    "\n",
    "So we now need two new formulas:\n",
    "\n",
    "5. The height of the pyramid using ([Pythagoras again](https://www.youtube.com/watch?v=ivF3ndmkMsE)): $h = \\sqrt{6}d/3$.\n",
    "6. The area of an equilateral triangle: $\\frac{\\sqrt{3}}{4} d^{2}$\n",
    "\n",
    "Triangular pyramids do *not* have a problem with mummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triangular pyramid ‰∏âÊ£±Èî•\n",
    "# Ê†πÂè∑6 Ôºö 6**(1/2)\n",
    "\n",
    "\n",
    "# Triangular Pyramid class\n",
    "class t_pyramid(shape): # Inherit from shape\n",
    "    \n",
    "    has_mummies = False # This is for *all* regular pyramids\n",
    "    \n",
    "    def __init__(self, dim:float):\n",
    "        super().__init__(dim)\n",
    "        self.shape_type = 'Triangular Pyramid'\n",
    "        return\n",
    "    \n",
    "    def diameter(self):\n",
    "        return self.dim\n",
    "    \n",
    "    def height(self):\n",
    "        return 6**(1/2)/3 * self.dim\n",
    "    \n",
    "    def base(self):\n",
    "        return 3**(1/2)/4 * self.dim**2\n",
    "       \n",
    "    def volume(self):\n",
    "        return (1/3) * self.base() * self.height()\n",
    "    \n",
    "    def surface(self):\n",
    "        return 4 * self.base()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.6 Testing Your Classes\n",
    "\n",
    "If you've implemented everything correctly then the following code should run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphere\n",
      "\tVolume is: 4188.79\n",
      "\tDiameter is: 20.00\n",
      "\tSurface Area is: 1256.64\n",
      "\n",
      "Cube\n",
      "\tVolume is: 1000.00\n",
      "\tDiameter is: 17.32\n",
      "\tSurface Area is: 600.00\n",
      "\n",
      "Regular Pyramid\n",
      "\tVolume is: 344.92\n",
      "\tDiameter is: 14.14\n",
      "\tSurface Area is: 273.21\n",
      "\tHeight is: 10.35\n",
      "\tMummies? Aaaaaaaaagh!\n",
      "\n",
      "Triangular Pyramid\n",
      "\tVolume is: 117.85\n",
      "\tDiameter is: 10.00\n",
      "\tSurface Area is: 173.21\n",
      "\tHeight is:  8.16\n",
      "\tPhew,¬†no¬†mummies!\n",
      "\n",
      "Shape¬†of¬†type¬†'Triangular Pyramid'¬†does¬†*not*¬†have¬†attribute¬†or¬†method¬†'base_area'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ê£ÄÊµã‰∏äÈù¢ÁªòÂà∂ÁöÑ 4 ‰∏™ÂõæÂΩ¢\n",
    "# Cube, Sphere, Regular Pyramid, Triangular Pyramid\n",
    "\n",
    "\n",
    "s = sphere(10)\n",
    "print(s.type())\n",
    "print(f\"\\tVolume is: {s.volume():5.2f}\")\n",
    "print(f\"\\tDiameter is: {s.diameter():5.2f}\")\n",
    "print(f\"\\tSurface Area is: {s.surface():5.2f}\")\n",
    "print(\"\")\n",
    "\n",
    "c = cube(10)\n",
    "print(c.type())\n",
    "print(f\"\\tVolume is: {c.volume():5.2f}\")\n",
    "print(f\"\\tDiameter is: {c.diameter():5.2f}\")\n",
    "print(f\"\\tSurface Area is: {c.surface():5.2f}\")\n",
    "print(\"\")\n",
    "\n",
    "p = pyramid(10)\n",
    "print(p.type())\n",
    "print(f\"\\tVolume is: {p.volume():5.2f}\")\n",
    "print(f\"\\tDiameter is: {p.diameter():5.2f}\")\n",
    "print(f\"\\tSurface Area is: {p.surface():5.2f}\")\n",
    "print(f\"\\tHeight is: {p.height():5.2f}\")\n",
    "if p.has_mummies is True:\n",
    "    print(\"\\tMummies? Aaaaaaaaagh!\")\n",
    "else:\n",
    "    print(\"\\tPhew, no mummies!\")\n",
    "print(\"\")\n",
    "\n",
    "p2 = t_pyramid(10)\n",
    "print(p2.type())\n",
    "print(f\"\\tVolume is: {p2.volume():5.2f}\")\n",
    "print(f\"\\tDiameter is: {p2.diameter():5.2f}\")\n",
    "print(f\"\\tSurface Area is: {p2.surface():5.2f}\")\n",
    "print(f\"\\tHeight is: {p2.height():5.2f}\")\n",
    "if p2.has_mummies is True:\n",
    "    print(\"\\tMummies?¬†Aaaaaaaaagh!\")\n",
    "else:\n",
    "    print(\"\\tPhew,¬†no¬†mummies!\")\n",
    "print(\"\")\n",
    "\n",
    "#¬†Useful¬†demonstration¬†of¬†how¬†to¬†find¬†out¬†if¬†a¬†method¬†or¬†attribute¬†is\n",
    "#¬†associated¬†with¬†a¬†particular¬†object\n",
    "if hasattr(p2,'base_area'):\n",
    "    print(f\"Shape¬†of¬†type '{p2.type()}'¬†has¬†attribute¬†or¬†method¬†'base_area'\")\n",
    "else:\n",
    "    print(f\"Shape¬†of¬†type¬†'{p2.type()}'¬†does¬†*not*¬†have¬†attribute¬†or¬†method¬†'base_area'\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I get the following output:\n",
    "\n",
    "```\n",
    "Sphere\n",
    "\tVolume is: 4188.79\n",
    "\tDiameter is: 20.00\n",
    "\tSurface Area is: 1256.64\n",
    "\n",
    "Cube\n",
    "\tVolume is: 1000.00\n",
    "\tDiameter is: 17.32\n",
    "\tSurface Area is: 600.00\n",
    "\n",
    "Regular Pyramid\n",
    "\tVolume is: 344.92\n",
    "\tDiameter is: 14.14\n",
    "\tSurface Area is: 273.21\n",
    "\tHeight is: 10.35\n",
    "\tMummies? Aaaaaaaaagh!\n",
    "\n",
    "Triangular Pyramid\n",
    "\tVolume is: 117.85\n",
    "\tDiameter is: 10.00\n",
    "\tSurface Area is: 173.21\n",
    "\tHeight is:  8.16\n",
    "\tPhew, no mummies!\n",
    "\n",
    "Shape of type 'Triangular Pyramid' does *not* have attribute or method 'base_area'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.7 Packaging It Up\n",
    "\n",
    "Wait, you're *still* working on this practical and haven't thrown up your hands in disgust yet? OK, in that case you can have *one* more thing to do: turn the whole shapes class hierarchy into a package that can be loaded via an `import` statement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7.1 Cell Magic\n",
    "\n",
    "This code allows Jupyter to reload external libraries if they are edited after you import them. When you are working on your own packages this is rather useful since you tend to make a *lot* of mistakes when packaging code up this way and it's handy not to have to restart the entire notebook every time you fix a typo or change a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7.2 Import Shapes\n",
    "\n",
    "You can call your package whatever you like, but then it *has* to match what you `import` below. So remember that with `dtools` we had `dtools/__init__.py`? You'll need to do the same here so that you can import the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# È¶ñÂÖàÔºåÈúÄË¶ÅÂú® _init_.py Êñá‰ª∂ÈáåÂÜôÂÖ•shapes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7.3 Adding Documentation\n",
    "\n",
    "In an ideal world, this would also be the time to properly document your classes and methods. Here as some examples that you could add to the `__init__.py` package file.\n",
    "\n",
    "Underneath the line `class shape(object):`, add:\n",
    "```\n",
    "    \"\"\"Abstract base class for all ideal shape classes.\n",
    "\n",
    "    Keyword arguments:\n",
    "    dimension -- the principle dimension of the shape (default None)\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "Underneath the line `def type(self):`, add:\n",
    "```\n",
    "        \"\"\"\n",
    "        Returns the formatted name of the shape type. \n",
    "        \n",
    "        This is set automatically, but can be overwritten by setting the attribute shape_type.\n",
    "        \n",
    "        :returns: the name of the class, so shapes.cube is a `Cube` shape type\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapes # <-- Change this if you didn't call your package `shapes`!\n",
    "help(shapes.shape)\n",
    "help(shapes.shape.type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
